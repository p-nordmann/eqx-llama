{
    "name": "eqx-llama",
    "dockerFile": "Dockerfile",
    "runArgs": [
        "--network=host",
        "--ipc=host",
        "--gpus=all"
    ],
    "postCreateCommand": "sh .devcontainer/post_create.sh",
    "customizations": {
        "vscode": {
            "extensions": [
                "ms-python.python",
                "ms-python.black-formatter",
                "ms-python.isort",
                "tamasfe.even-better-toml"
            ],
            "settings": {
                "python.formatting.provider": "black",
                "[python]": {
                    "editor.formatOnSave": true,
                    "editor.codeActionsOnSave": {
                        "source.organizeImports": "explicit"
                    }
                },
                "python.analysis.extraPaths": [
                    "/opt/equinox",
                    "/opt/flax",
                    "/opt/jax",
                    "/opt/jaxlibs/jax_gpu_pjrt",
                    "/opt/jaxlibs/jax_gpu_plugin",
                    "/opt/jax_nsys/python/jax_nsys",
                    "/opt/jaxlibs/jaxlib"
                ],
                "files.exclude": {
                    "**/.git": true,
                    "**/.svn": true,
                    "**/.hg": true,
                    "**/CVS": true,
                    "**/.DS_Store": true,
                    "**/Thumbs.db": true,
                    "**/*.egg-info": true,
                    "**/.pytest_cache": true,
                    "**/__pycache__": true
                }
            }
        }
    }
}